ADR-002 — Modelo de Embeddings
Contexto

O sistema RAG depende de embeddings de boa qualidade para recuperar trechos relevantes do regulamento da pós-graduação. O modelo precisa funcionar bem em português, ser rápido o bastante para rodar no Google Colab sem GPU e manter boa coerência semântica nos vetores gerados.

Decisão

Adotar o modelo paraphrase-multilingual-MiniLM-L12-v2 do Sentence-Transformers.

Razões

Compatível com português brasileiro, reduzindo perdas semânticas comuns em modelos monolíngues.

MiniLM → baixo custo computacional, execução eficiente em CPU.

Boa qualidade semântica para tarefas de similaridade e retrieval.

Modelo amplamente usado e estabilizado, reduzindo risco de comportamento inesperado.

Alternativas Rejeitadas

Modelos maiores (e.g., mpnet-large, LaBSE): melhor qualidade, porém inviáveis sem GPU devido à lentidão.

Modelos apenas em inglês (e.g., all-mpnet-base-v2): perda significativa de precisão na recuperação de conteúdo em PT-BR.

Consequências

Embeddings rápidos de gerar e com boa qualidade semântica.

Pipeline mais leve, adequado ao ambiente de execução.