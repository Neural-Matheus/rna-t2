{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BsFag1W82RVj"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "import chromadb\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "from groq import Groq\n",
        "from google.colab import userdata\n",
        "from datetime import datetime\n",
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4TJPyPJ4Drm"
      },
      "outputs": [],
      "source": [
        "class RAGChatbot:\n",
        "    def __init__(self,\n",
        "                 chroma_persist_dir: str = \"/content/chroma_db\",\n",
        "                 chroma_collection_name: str = \"facom_regulamento\",\n",
        "                 bi_encoder_name: str = \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
        "                 cross_encoder_name: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
        "                 groq_model: str = \"llama-3.3-70b-versatile\",\n",
        "                 device: str = \"cpu\",\n",
        "                 enable_fact_score: bool = False):\n",
        "\n",
        "        self.client = chromadb.PersistentClient(path=chroma_persist_dir)\n",
        "        self.collection = self.client.get_collection(chroma_collection_name)\n",
        "\n",
        "        self.bi_encoder = SentenceTransformer(bi_encoder_name, device=device)\n",
        "        self.cross_encoder = CrossEncoder(cross_encoder_name, device=device)\n",
        "\n",
        "        self.groq_client = Groq(api_key=\"\")\n",
        "        self.groq_model = groq_model\n",
        "\n",
        "        self.conversation_history = []\n",
        "        self.total_tokens = 0\n",
        "        self.enable_fact_score = enable_fact_score\n",
        "        self.fact_scores_history = []\n",
        "\n",
        "        print(f\"ü§ñ Chatbot inicializado!\")\n",
        "        print(f\"üìö Base: {chroma_collection_name} ({self.collection.count()} documentos)\")\n",
        "        print(f\"üß† Modelo: {groq_model}\")\n",
        "        print(f\"‚úì Fact Score: {'Ativado' if enable_fact_score else 'Desativado'}\\n\")\n",
        "\n",
        "    def retrieve_candidates(self, query: str, top_k: int = 20) -> Dict[str, Any]:\n",
        "        q_vec = self.bi_encoder.encode([query], convert_to_numpy=True)[0].tolist()\n",
        "        res = self.collection.query(\n",
        "            query_embeddings=[q_vec],\n",
        "            n_results=top_k,\n",
        "            include=[\"documents\", \"distances\", \"metadatas\"]\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"ids\": res[\"ids\"][0],\n",
        "            \"docs\": res[\"documents\"][0],\n",
        "            \"distances\": res[\"distances\"][0],\n",
        "            \"metadatas\": res.get(\"metadatas\", [None])[0]\n",
        "        }\n",
        "\n",
        "    def rerank(self, query: str, docs: List[str]) -> List[Tuple[float, int]]:\n",
        "        if not docs:\n",
        "            return []\n",
        "        pairs = [[query, d] for d in docs]\n",
        "        scores = self.cross_encoder.predict(pairs)\n",
        "        scored = [(float(s), int(i)) for i, s in enumerate(scores)]\n",
        "        return sorted(scored, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    def retrieve_and_rerank(self, query: str, retrieve_k: int = 20, final_k: int = 3) -> List[Dict[str, Any]]:\n",
        "        candidates = self.retrieve_candidates(query, top_k=retrieve_k)\n",
        "\n",
        "        if not candidates[\"docs\"]:\n",
        "            return []\n",
        "\n",
        "        reranked = self.rerank(query, candidates[\"docs\"])\n",
        "\n",
        "        results = []\n",
        "        for score, idx in reranked[:final_k]:\n",
        "            results.append({\n",
        "                \"text\": candidates[\"docs\"][idx],\n",
        "                \"score\": float(score),\n",
        "                \"metadata\": candidates[\"metadatas\"][idx]\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def decompose_into_facts(self, answer: str) -> List[str]:\n",
        "        prompt = f\"\"\"Decomponha a resposta abaixo em afirma√ß√µes at√¥micas independentes.\n",
        "          Cada afirma√ß√£o deve ser uma unidade de informa√ß√£o que pode ser verificada individualmente.\n",
        "\n",
        "          REGRAS:\n",
        "          - Uma afirma√ß√£o por linha\n",
        "          - Cada afirma√ß√£o deve ser auto-contida\n",
        "          - N√£o adicione informa√ß√µes que n√£o est√£o na resposta\n",
        "          - Numere cada afirma√ß√£o (1., 2., 3., etc.)\n",
        "\n",
        "          RESPOSTA A DECOMPOR:\n",
        "          {answer}\n",
        "\n",
        "          AFIRMA√á√ïES AT√îMICAS:\"\"\"\n",
        "\n",
        "        response = self.groq_client.chat.completions.create(\n",
        "            model=self.groq_model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Voc√™ √© um especialista em decomposi√ß√£o de texto em afirma√ß√µes at√¥micas.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.1,\n",
        "            max_tokens=1024\n",
        "        )\n",
        "\n",
        "        decomposition = response.choices[0].message.content\n",
        "\n",
        "        facts = []\n",
        "        for line in decomposition.split('\\n'):\n",
        "            line = line.strip()\n",
        "            match = re.match(r'^\\d+\\.\\s*(.+)', line)\n",
        "            if match:\n",
        "                facts.append(match.group(1).strip())\n",
        "\n",
        "        return facts\n",
        "\n",
        "    def verify_fact(self, fact: str, context_docs: List[str]) -> Dict[str, Any]:\n",
        "        context = \"\\n\\n\".join([f\"[Documento {i+1}]\\n{doc}\" for i, doc in enumerate(context_docs)])\n",
        "\n",
        "        prompt = f\"\"\"Voc√™ deve verificar se a AFIRMA√á√ÉO abaixo √© suportada pelos DOCUMENTOS fornecidos.\n",
        "\n",
        "          DOCUMENTOS:\n",
        "          {context}\n",
        "\n",
        "          AFIRMA√á√ÉO:\n",
        "          {fact}\n",
        "\n",
        "          Responda APENAS com um JSON no seguinte formato (sem markdown, sem explica√ß√µes extras):\n",
        "          {{\n",
        "              \"supported\": true ou false,\n",
        "              \"confidence\": \"high\", \"medium\" ou \"low\",\n",
        "              \"explanation\": \"breve explica√ß√£o de 1-2 frases\"\n",
        "          }}\n",
        "\n",
        "          IMPORTANTE:\n",
        "          - \"supported\": true apenas se a afirma√ß√£o est√° claramente nos documentos\n",
        "          - \"supported\": false se contradiz ou n√£o est√° nos documentos\n",
        "          - \"confidence\": seu n√≠vel de certeza na verifica√ß√£o\"\"\"\n",
        "\n",
        "        response = self.groq_client.chat.completions.create(\n",
        "            model=self.groq_model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Voc√™ √© um verificador de fatos preciso. Responda APENAS com JSON v√°lido.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.1,\n",
        "            max_tokens=256\n",
        "        )\n",
        "\n",
        "        result_text = response.choices[0].message.content.strip()\n",
        "        result_text = re.sub(r'```json\\s*|\\s*```', '', result_text).strip()\n",
        "\n",
        "        try:\n",
        "            result = json.loads(result_text)\n",
        "            return result\n",
        "        except json.JSONDecodeError:\n",
        "            return {\n",
        "                \"supported\": False,\n",
        "                \"confidence\": \"low\",\n",
        "                \"explanation\": \"Erro ao processar verifica√ß√£o\"\n",
        "            }\n",
        "\n",
        "    def calculate_fact_score(self, answer: str, context_docs: List[str]) -> Dict[str, Any]:\n",
        "        facts = self.decompose_into_facts(answer)\n",
        "\n",
        "        if not facts:\n",
        "            return {\n",
        "                \"fact_score\": 1.0,\n",
        "                \"total_facts\": 0,\n",
        "                \"supported_facts\": 0,\n",
        "                \"details\": []\n",
        "            }\n",
        "\n",
        "        verifications = []\n",
        "        supported_count = 0\n",
        "\n",
        "        for fact in facts:\n",
        "            verification = self.verify_fact(fact, context_docs)\n",
        "            verification['fact'] = fact\n",
        "            verifications.append(verification)\n",
        "\n",
        "            if verification['supported']:\n",
        "                supported_count += 1\n",
        "\n",
        "        fact_score = supported_count / len(facts) if facts else 0.0\n",
        "\n",
        "        return {\n",
        "            \"fact_score\": round(fact_score, 3),\n",
        "            \"total_facts\": len(facts),\n",
        "            \"supported_facts\": supported_count,\n",
        "            \"unsupported_facts\": len(facts) - supported_count,\n",
        "            \"details\": verifications\n",
        "        }\n",
        "\n",
        "    def chat(self,\n",
        "             user_message: str,\n",
        "             use_rag: bool = True,\n",
        "             retrieve_k: int = 20,\n",
        "             final_k: int = 3,\n",
        "             temperature: float = 0.5,\n",
        "             max_tokens: int = 1024,\n",
        "             calculate_fact_score: bool = None) -> Dict[str, Any]:\n",
        "\n",
        "        if calculate_fact_score is None:\n",
        "            calculate_fact_score = self.enable_fact_score\n",
        "\n",
        "        self.conversation_history.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_message,\n",
        "            \"timestamp\": datetime.now().strftime(\"%H:%M:%S\")\n",
        "        })\n",
        "\n",
        "        messages = []\n",
        "        context_docs_list = []\n",
        "\n",
        "        system_prompt = \"\"\"Voc√™ √© um assistente virtual especializado no regulamento acad√™mico da FACOM/UFMS (Faculdade de Computa√ß√£o da Universidade Federal de Mato Grosso do Sul).\n",
        "\n",
        "          Caracter√≠sticas:\n",
        "          - Amig√°vel e prestativo\n",
        "          - Responde em portugu√™s brasileiro\n",
        "          - Usa linguagem clara e acess√≠vel\n",
        "          - Quando usa RAG, baseia-se apenas nas informa√ß√µes fornecidas\n",
        "          - Quando n√£o usa RAG, pode conversar naturalmente sobre t√≥picos gerais\n",
        "          - Admite quando n√£o sabe algo\n",
        "          - Mant√©m contexto da conversa anterior\"\"\"\n",
        "\n",
        "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "\n",
        "        if use_rag:\n",
        "            context_docs = self.retrieve_and_rerank(user_message, retrieve_k, final_k)\n",
        "\n",
        "            if context_docs:\n",
        "                context_docs_list = [doc['text'] for doc in context_docs]\n",
        "                context = \"\\n\\n\".join([\n",
        "                    f\"[Documento {i+1}]\\n{doc['text']}\"\n",
        "                    for i, doc in enumerate(context_docs)\n",
        "                ])\n",
        "\n",
        "                rag_instruction = f\"\"\"CONTEXTO DO REGULAMENTO:\n",
        "                  {context}\n",
        "\n",
        "                  Use as informa√ß√µes acima para responder a pergunta do usu√°rio. Se a informa√ß√£o n√£o estiver no contexto, diga que n√£o encontrou.\"\"\"\n",
        "\n",
        "                messages.append({\"role\": \"system\", \"content\": rag_instruction})\n",
        "\n",
        "        recent_history = self.conversation_history[-7:-1]\n",
        "        for msg in recent_history:\n",
        "            messages.append({\n",
        "                \"role\": msg[\"role\"],\n",
        "                \"content\": msg[\"content\"]\n",
        "            })\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "        response = self.groq_client.chat.completions.create(\n",
        "            model=self.groq_model,\n",
        "            messages=messages,\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "\n",
        "        assistant_message = response.choices[0].message.content\n",
        "        tokens_used = response.usage.total_tokens\n",
        "        self.total_tokens += tokens_used\n",
        "\n",
        "        fact_score_result = None\n",
        "        if calculate_fact_score and use_rag and context_docs_list:\n",
        "            fact_score_result = self.calculate_fact_score(assistant_message, context_docs_list)\n",
        "            self.fact_scores_history.append({\n",
        "                \"question\": user_message,\n",
        "                \"answer\": assistant_message,\n",
        "                \"fact_score\": fact_score_result['fact_score'],\n",
        "                \"timestamp\": datetime.now().strftime(\"%H:%M:%S\")\n",
        "            })\n",
        "\n",
        "        self.conversation_history.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": assistant_message,\n",
        "            \"timestamp\": datetime.now().strftime(\"%H:%M:%S\"),\n",
        "            \"tokens\": tokens_used,\n",
        "            \"fact_score\": fact_score_result['fact_score'] if fact_score_result else None\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            \"answer\": assistant_message,\n",
        "            \"tokens\": tokens_used,\n",
        "            \"fact_score\": fact_score_result\n",
        "        }\n",
        "\n",
        "    def clear_history(self):\n",
        "        self.conversation_history = []\n",
        "        self.total_tokens = 0\n",
        "        self.fact_scores_history = []\n",
        "        print(\"üóëÔ∏è  Hist√≥rico limpo!\")\n",
        "\n",
        "    def show_history(self):\n",
        "        if not self.conversation_history:\n",
        "            print(\"Nenhuma mensagem no hist√≥rico.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"HIST√ìRICO DE CONVERSA√á√ÉO\")\n",
        "        print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "        for msg in self.conversation_history:\n",
        "            role = \"üë§ Voc√™\" if msg[\"role\"] == \"user\" else \"ü§ñ Assistente\"\n",
        "            time = msg.get(\"timestamp\", \"\")\n",
        "            tokens = f\" ({msg['tokens']} tokens)\" if \"tokens\" in msg else \"\"\n",
        "            fact_score = f\" [Fact Score: {msg.get('fact_score', 'N/A')}]\" if msg.get('fact_score') is not None else \"\"\n",
        "\n",
        "            print(f\"{role} [{time}]{tokens}{fact_score}\")\n",
        "            print(msg[\"content\"])\n",
        "            print(\"-\"*80 + \"\\n\")\n",
        "\n",
        "        print(f\"Total de tokens usados: {self.total_tokens}\")\n",
        "\n",
        "    def show_fact_scores(self):\n",
        "        if not self.fact_scores_history:\n",
        "            print(\"Nenhum Fact Score calculado ainda.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"HIST√ìRICO DE FACT SCORES\")\n",
        "        print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "        for i, entry in enumerate(self.fact_scores_history, 1):\n",
        "            print(f\"[{i}] {entry['timestamp']} - Score: {entry['fact_score']:.3f}\")\n",
        "            print(f\"Q: {entry['question'][:70]}...\")\n",
        "            print(f\"A: {entry['answer'][:70]}...\")\n",
        "            print(\"-\"*80 + \"\\n\")\n",
        "\n",
        "        avg_score = sum(e['fact_score'] for e in self.fact_scores_history) / len(self.fact_scores_history)\n",
        "        print(f\"üìä Fact Score m√©dio: {avg_score:.3f}\")\n",
        "\n",
        "    def get_stats(self):\n",
        "        stats = {\n",
        "            \"total_messages\": len(self.conversation_history),\n",
        "            \"user_messages\": len([m for m in self.conversation_history if m[\"role\"] == \"user\"]),\n",
        "            \"assistant_messages\": len([m for m in self.conversation_history if m[\"role\"] == \"assistant\"]),\n",
        "            \"total_tokens\": self.total_tokens\n",
        "        }\n",
        "\n",
        "        if self.fact_scores_history:\n",
        "            avg_fact_score = sum(e['fact_score'] for e in self.fact_scores_history) / len(self.fact_scores_history)\n",
        "            stats[\"avg_fact_score\"] = round(avg_fact_score, 3)\n",
        "            stats[\"total_fact_scores\"] = len(self.fact_scores_history)\n",
        "\n",
        "        return stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gNJolOZ35icS"
      },
      "outputs": [],
      "source": [
        "def run_chatbot(chroma_persist_dir: str = \"/content/chroma_db\",\n",
        "                chroma_collection_name: str = \"facom_regulamento\",\n",
        "                enable_fact_score: bool = False):\n",
        "\n",
        "    chatbot = RAGChatbot(\n",
        "        chroma_persist_dir=chroma_persist_dir,\n",
        "        chroma_collection_name=chroma_collection_name,\n",
        "        device=\"cpu\",\n",
        "        enable_fact_score=enable_fact_score\n",
        "    )\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"üéì CHATBOT - REGULAMENTO FACOM/UFMS\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nComandos especiais:\")\n",
        "    print(\"  /sair          - Encerrar o chat\")\n",
        "    print(\"  /limpar        - Limpar hist√≥rico\")\n",
        "    print(\"  /historico     - Ver hist√≥rico completo\")\n",
        "    print(\"  /stats         - Ver estat√≠sticas\")\n",
        "    print(\"  /factscores    - Ver hist√≥rico de Fact Scores\")\n",
        "    print(\"  /norag         - Pr√≥xima pergunta SEM buscar no regulamento\")\n",
        "    print(\"  /factscore     - Calcular Fact Score na pr√≥xima resposta\")\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "    use_rag_next = True\n",
        "    calc_fact_score_next = None\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"üë§ Voc√™: \").strip()\n",
        "\n",
        "            if not user_input:\n",
        "                continue\n",
        "\n",
        "            if user_input.lower() == \"/sair\":\n",
        "                print(\"\\nüëã At√© logo! Espero ter ajudado.\")\n",
        "                stats = chatbot.get_stats()\n",
        "                print(f\"üìä Estat√≠sticas: {stats['user_messages']} perguntas, {stats['total_tokens']} tokens usados\")\n",
        "                if 'avg_fact_score' in stats:\n",
        "                    print(f\"   Fact Score m√©dio: {stats['avg_fact_score']}\")\n",
        "                break\n",
        "\n",
        "            elif user_input.lower() == \"/limpar\":\n",
        "                chatbot.clear_history()\n",
        "                continue\n",
        "\n",
        "            elif user_input.lower() == \"/historico\":\n",
        "                chatbot.show_history()\n",
        "                continue\n",
        "\n",
        "            elif user_input.lower() == \"/factscores\":\n",
        "                chatbot.show_fact_scores()\n",
        "                continue\n",
        "\n",
        "            elif user_input.lower() == \"/stats\":\n",
        "                stats = chatbot.get_stats()\n",
        "                print(f\"\\nüìä Estat√≠sticas:\")\n",
        "                print(f\"   - Total de mensagens: {stats['total_messages']}\")\n",
        "                print(f\"   - Suas perguntas: {stats['user_messages']}\")\n",
        "                print(f\"   - Respostas do bot: {stats['assistant_messages']}\")\n",
        "                print(f\"   - Tokens usados: {stats['total_tokens']}\")\n",
        "                if 'avg_fact_score' in stats:\n",
        "                    print(f\"   - Fact Score m√©dio: {stats['avg_fact_score']}\")\n",
        "                    print(f\"   - Total de avalia√ß√µes: {stats['total_fact_scores']}\")\n",
        "                print()\n",
        "                continue\n",
        "\n",
        "            elif user_input.lower() == \"/norag\":\n",
        "                use_rag_next = False\n",
        "                print(\"‚úì Pr√≥xima resposta ser√° SEM busca no regulamento\\n\")\n",
        "                continue\n",
        "\n",
        "            elif user_input.lower() == \"/factscore\":\n",
        "                calc_fact_score_next = True\n",
        "                print(\"‚úì Fact Score ser√° calculado na pr√≥xima resposta\\n\")\n",
        "                continue\n",
        "\n",
        "            print(\"ü§ñ Assistente: \", end=\"\", flush=True)\n",
        "\n",
        "            result = chatbot.chat(\n",
        "                user_input,\n",
        "                use_rag=use_rag_next,\n",
        "                temperature=0.5,\n",
        "                calculate_fact_score=calc_fact_score_next\n",
        "            )\n",
        "\n",
        "            print(result['answer'])\n",
        "\n",
        "            if result['fact_score']:\n",
        "                fs = result['fact_score']\n",
        "                print(f\"\\nüìä Fact Score: {fs['fact_score']:.3f} ({fs['supported_facts']}/{fs['total_facts']} afirma√ß√µes suportadas)\")\n",
        "\n",
        "            print()\n",
        "\n",
        "            use_rag_next = True\n",
        "            calc_fact_score_next = None\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nüëã Chat interrompido. At√© logo!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Erro: {e}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ok5t9kC5mK_",
        "outputId": "27b8f170-318b-41f5-aea9-1a63098e18f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Chatbot inicializado!\n",
            "üìö Base: facom_regulamento (62 documentos)\n",
            "üß† Modelo: llama-3.3-70b-versatile\n",
            "‚úì Fact Score: Desativado\n",
            "\n",
            "================================================================================\n",
            "üéì CHATBOT - REGULAMENTO FACOM/UFMS\n",
            "================================================================================\n",
            "\n",
            "Comandos especiais:\n",
            "  /sair          - Encerrar o chat\n",
            "  /limpar        - Limpar hist√≥rico\n",
            "  /historico     - Ver hist√≥rico completo\n",
            "  /stats         - Ver estat√≠sticas\n",
            "  /factscores    - Ver hist√≥rico de Fact Scores\n",
            "  /norag         - Pr√≥xima pergunta SEM buscar no regulamento\n",
            "  /factscore     - Calcular Fact Score na pr√≥xima resposta\n",
            "\n",
            "================================================================================\n",
            "\n",
            "üë§ Voc√™: Quando o regulamento entra em vigor?\n",
            "ü§ñ Assistente: De acordo com o Art. 3¬∫ do regulamento, ele entra em vigor em 1¬∫ de janeiro de 2026. Essa informa√ß√£o est√° presente em ambos os Documentos 1 e 2.\n",
            "\n",
            "üë§ Voc√™: /factscore\n",
            "‚úì Fact Score ser√° calculado na pr√≥xima resposta\n",
            "\n",
            "üë§ Voc√™: Quando o regulamento entra em vigor?\n",
            "ü§ñ Assistente: O regulamento entra em vigor em 1¬∫ de janeiro de 2026, conforme estabelecido no Art. 3¬∫.\n",
            "\n",
            "üìä Fact Score: 1.000 (2/2 afirma√ß√µes suportadas)\n",
            "\n",
            "üë§ Voc√™: O que o Doutorado Profissional deve promover?\n",
            "ü§ñ Assistente: De acordo com o Art. 2¬∫, o Doutorado Profissional deve capacitar profissionais qualificados para o exerc√≠cio da pr√°tica profissional avan√ßada, a fim de atender arranjos produtivos em empresas, organiza√ß√µes p√∫blicas e privadas.\n",
            "\n",
            "üë§ Voc√™: /factscore\n",
            "‚úì Fact Score ser√° calculado na pr√≥xima resposta\n",
            "\n",
            "üë§ Voc√™: O que o Doutorado Profissional deve promover?\n",
            "ü§ñ Assistente: De acordo com o Art. 2¬∫, o Doutorado Profissional deve promover a capacita√ß√£o de profissionais qualificados para o exerc√≠cio da pr√°tica profissional avan√ßada, visando atender √†s demandas de empresas, organiza√ß√µes p√∫blicas e privadas.\n",
            "\n",
            "üìä Fact Score: 1.000 (6/6 afirma√ß√µes suportadas)\n",
            "\n",
            "üë§ Voc√™: /factscore\n",
            "‚úì Fact Score ser√° calculado na pr√≥xima resposta\n",
            "\n",
            "üë§ Voc√™: Quais s√£o as caracter√≠scas principais dos Cursos\n",
            "ü§ñ Assistente: N√£o encontrei informa√ß√µes espec√≠ficas sobre as caracter√≠sticas principais dos Cursos no texto fornecido. Se voc√™ tiver mais detalhes ou contexto, posso tentar ajudar melhor.\n",
            "\n",
            "üìä Fact Score: 0.000 (0/2 afirma√ß√µes suportadas)\n",
            "\n",
            "üë§ Voc√™:  √â poss√≠vel cursar o doutorado direto ap√≥s a gradua√ß√£o, sem ter realizado o Curso de Mestrado\n",
            "ü§ñ Assistente: Sim, √© poss√≠vel cursar o doutorado direto ap√≥s a gradua√ß√£o, sem ter realizado o Curso de Mestrado, de acordo com o Art. 3¬∫. No entanto, o ingresso no doutorado direto ser√° regulamentado por ato da Pr√≥-Reitoria de Pesquisa e P√≥s-Gradua√ß√£o.\n",
            "\n",
            "üë§ Voc√™: /factscore\n",
            "‚úì Fact Score ser√° calculado na pr√≥xima resposta\n",
            "\n",
            "üë§ Voc√™:  √â poss√≠vel cursar o doutorado direto ap√≥s a gradua√ß√£o, sem ter realizado o Curso de Mestrado?\n",
            "ü§ñ Assistente: Sim, √© poss√≠vel. De acordo com o Art. 3¬∫, √© poss√≠vel cursar o doutorado direto ap√≥s a gradua√ß√£o, sem ter realizado o Curso de Mestrado. Al√©m disso, o Art. 29, ¬ß 1¬∫, tamb√©m menciona que poder√£o ser aceitas inscri√ß√µes para o processo seletivo no doutorado sem a exig√™ncia do grau de Mestre.\n",
            "\n",
            "üìä Fact Score: 1.000 (4/4 afirma√ß√µes suportadas)\n",
            "\n",
            "üë§ Voc√™: /factscore\n",
            "‚úì Fact Score ser√° calculado na pr√≥xima resposta\n",
            "\n",
            "üë§ Voc√™: O funcionamento de Curso recomendado pela Coordena√ß√£o de Aperfei√ßoamento de Pessoal de N√≠vel Superior, tem in√≠cio com a matr√≠cula dos estudantes, ap√≥s o qu√™?\n",
            "ü§ñ Assistente: De acordo com o Art. 6¬∫, o funcionamento de Curso recomendado pela Coordena√ß√£o de Aperfei√ßoamento de Pessoal de N√≠vel Superior, tem in√≠cio com a matr√≠cula dos estudantes, ap√≥s:\n",
            "\n",
            "I - autoriza√ß√£o e o reconhecimento do curso pela C√¢mara de Educa√ß√£o Superior do Conselho Nacional de Educa√ß√£o - CES/CNE, homologados pelo Ministro da Educa√ß√£o;\n",
            "II - constitui√ß√£o do Colegiado de Curso e designa√ß√£o do Coordenador, observando-se o disposto no Regimento Geral e no Estatuto da UFMS;\n",
            "III - aprova√ß√£o do Regulamento dos Cursos de P√≥s-Gradua√ß√£o stricto sensu;\n",
            "IV - cadastramento do Curso no Sistema Acad√™mico; e\n",
            "V - homologa√ß√£o do processo seletivo dos candidatos, pela Pr√≥-Reitoria de Pesquisa e P√≥s-Gradua√ß√£o.\n",
            "\n",
            "üìä Fact Score: 1.000 (10/10 afirma√ß√µes suportadas)\n",
            "\n",
            "üë§ Voc√™: /sair\n",
            "\n",
            "üëã At√© logo! Espero ter ajudado.\n",
            "üìä Estat√≠sticas: 8 perguntas, 11005 tokens usados\n",
            "   Fact Score m√©dio: 0.8\n"
          ]
        }
      ],
      "source": [
        "run_chatbot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
